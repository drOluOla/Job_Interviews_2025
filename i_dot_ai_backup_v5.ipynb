{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drOluOla/Job_Interviews_2025/blob/main/i_dot_ai_backup_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sLnO0O7ungqw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7jQ7qj5pu2C",
        "outputId": "cacc881c-bc04-4c86-dc5b-fcf32836b150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-agents[voice] in /usr/local/lib/python3.11/dist-packages (0.0.16)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (1.7.3)\n",
            "Requirement already satisfied: mcp<2,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (1.9.1)\n",
            "Requirement already satisfied: openai>=1.81.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (1.82.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (2.32.3)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (2.32.0.20250515)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (4.13.2)\n",
            "Collecting numpy<3,>=2.2.0 (from openai-agents[voice])\n",
            "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: websockets<16,>=15.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents[voice]) (15.0.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe<2,>=1.5.6->openai-agents[voice]) (0.4.6)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (4.9.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (0.4.0)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (0.28.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (2.9.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (2.3.5)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (0.46.2)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents[voice]) (0.34.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.81.0->openai-agents[voice]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.81.0->openai-agents[voice]) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.81.0->openai-agents[voice]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.81.0->openai-agents[voice]) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents[voice]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents[voice]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents[voice]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents[voice]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents[voice]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents[voice]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents[voice]) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.8.0->openai-agents[voice]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.8.0->openai-agents[voice]) (0.16.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.8.0->openai-agents[voice]) (1.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.8.0->openai-agents[voice]) (8.2.0)\n",
            "Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.6\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "Successfully installed numpy-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-agents[voice]\n",
        "!pip install gradio numpy librosa soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jl8VZIL7ssqG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from agents import Agent, Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Oz8heNa4p00l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dafdbf-be23-4e15-c941-04f914eaa2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of now, the President of Nigeria is Bola Ahmed Tinubu. He took office on May 29, 2023.\n"
          ]
        }
      ],
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    result = await Runner.run(agent, \"Who is the president of nigeria\")\n",
        "    print(result.final_output)\n",
        "else:\n",
        "    print(\"Please set the OPENAI_API_KEY environment variable in Colab Secrets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import asyncio\n",
        "import random\n",
        "import io\n",
        "import wave\n",
        "import openai\n",
        "from typing import AsyncIterator, Optional, Tuple, Dict, Any\n",
        "from agents import Agent, Runner, function_tool\n",
        "from agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# --- Voice Configuration for Different Agents ---\n",
        "AGENT_VOICES = {\n",
        "    \"HRManager\": {\n",
        "        \"voice\": \"alloy\",\n",
        "        \"speed\": 1.0,\n",
        "        \"description\": \"Professional & Welcoming\",\n",
        "        \"emoji\": \"üë©‚Äçüíº\",\n",
        "        \"color\": \"#FF6B6B\",\n",
        "        \"specialty\": \"HR Policies & Benefits\"\n",
        "    },\n",
        "    \"ITStaff\": {\n",
        "        \"voice\": \"sage\",\n",
        "        \"speed\": 1.1,\n",
        "        \"description\": \"Technical & Helpful\",\n",
        "        \"emoji\": \"üíª\",\n",
        "        \"color\": \"#4ECDC4\",\n",
        "        \"specialty\": \"IT Setup & Support\"\n",
        "    },\n",
        "    \"LineManager\": {\n",
        "        \"voice\": \"echo\",\n",
        "        \"speed\": 1.0,\n",
        "        \"description\": \"Supportive & Strategic\",\n",
        "        \"emoji\": \"üìä\",\n",
        "        \"color\": \"#45B7B8\",\n",
        "        \"specialty\": \"Team Leadership & Goals\"\n",
        "    },\n",
        "    \"AIColleague\": {\n",
        "        \"voice\": \"nova\",\n",
        "        \"speed\": 1.0,\n",
        "        \"description\": \"Friendly & Collaborative\",\n",
        "        \"emoji\": \"ü§ñ\",\n",
        "        \"color\": \"#95E1D3\",\n",
        "        \"specialty\": \"General Workplace Support\"\n",
        "    }\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class UserData:\n",
        "    \"\"\"Shared state across all agents\"\"\"\n",
        "    active_agent_type: Optional[str] = None\n",
        "    conversation_history: list = field(default_factory=list)\n",
        "    prev_agent_type: Optional[str] = None\n",
        "\n",
        "    # Employee onboarding data\n",
        "    employee_name: str = \"\"\n",
        "    contract_signed: Optional[bool] = None\n",
        "    email: str = \"\"\n",
        "    onboarding_stage: str = \"welcome\"\n",
        "\n",
        "    # Additional context\n",
        "    last_transcript: str = \"\"\n",
        "    user_intent: str = \"\"\n",
        "    turn_count: int = 0\n",
        "    last_messages: Dict[str, str] = field(default_factory=dict)\n",
        "\n",
        "    def log_response(self, agent_name: str, message: str):\n",
        "        \"\"\"Log agent response\"\"\"\n",
        "        self.active_agent_type = agent_name\n",
        "        self.conversation_history.append({\"agent\": agent_name, \"message\": message})\n",
        "        self.last_messages[agent_name] = message\n",
        "        self.turn_count += 1\n",
        "\n",
        "def generate_speech(text: str, agent_name: str = \"HRManager\") -> bytes:\n",
        "    \"\"\"Generate speech with agent-specific voice characteristics\"\"\"\n",
        "    try:\n",
        "        voice_config = AGENT_VOICES.get(agent_name, AGENT_VOICES[\"HRManager\"])\n",
        "        print(f\"[debug] Generating speech for {agent_name} with voice '{voice_config['voice']}'\")\n",
        "\n",
        "        response = openai.audio.speech.create(\n",
        "            model=\"gpt-4o-mini-tts\",\n",
        "            voice=voice_config[\"voice\"],\n",
        "            input=text,\n",
        "            speed=voice_config[\"speed\"]\n",
        "        )\n",
        "        return response.content\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Speech generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_agent_avatar(agent_name: str, is_active: bool = False, last_message: str = \"\") -> str:\n",
        "    \"\"\"Create avatar for any agent with active/inactive states\"\"\"\n",
        "    config = AGENT_VOICES.get(agent_name, AGENT_VOICES[\"HRManager\"])\n",
        "\n",
        "    # Simple active/inactive styling\n",
        "    if is_active:\n",
        "        ring_style = f\"box-shadow: 0 0 20px {config['color']}; border-color: {config['color']}; animation: pulse 1s infinite;\"\n",
        "        bg_overlay = f\"{config['color']}20\"\n",
        "        status_text = '<div style=\"margin-top: 10px; color: #4CAF50; font-weight: bold;\">üé§ SPEAKING</div>'\n",
        "    else:\n",
        "        ring_style = \"\"\n",
        "        bg_overlay = \"rgba(255, 255, 255, 0.05)\"\n",
        "        status_text = \"\"\n",
        "\n",
        "    # Add last message preview if available\n",
        "    message_preview = \"\"\n",
        "    if last_message and len(last_message.strip()) > 0:\n",
        "        preview_text = last_message[:50] + \"...\" if len(last_message) > 50 else last_message\n",
        "        message_preview = f'''\n",
        "        <div style=\"\n",
        "            margin-top: 8px;\n",
        "            padding: 8px;\n",
        "            background: rgba(0,0,0,0.1);\n",
        "            border-radius: 8px;\n",
        "            font-size: 0.7em;\n",
        "            color: #555;\n",
        "            max-height: 40px;\n",
        "            overflow: hidden;\n",
        "            border-left: 3px solid {config['color']};\n",
        "        \">\n",
        "            \"{preview_text}\"\n",
        "        </div>'''\n",
        "\n",
        "    return f\"\"\"\n",
        "            <style>\n",
        "                @keyframes pulse {{\n",
        "                    0% {{ opacity: 1; }}\n",
        "                    50% {{ opacity: 0.7; }}\n",
        "                    100% {{ opacity: 1; }}\n",
        "                }}\n",
        "            </style>\n",
        "            <div style=\"\n",
        "                text-align: center;\n",
        "                padding: 20px;\n",
        "                border-radius: 15px;\n",
        "                background: linear-gradient(135deg, {config['color']}20, {config['color']}10);\n",
        "                border: 3px solid {config['color']};\n",
        "                {ring_style}\n",
        "                transition: all 0.3s ease;\n",
        "                height: 220px;\n",
        "                display: flex;\n",
        "                flex-direction: column;\n",
        "                justify-content: center;\n",
        "                align-items: center;\n",
        "                position: relative;\n",
        "                overflow: hidden;\n",
        "            \">\n",
        "                <div style=\"\n",
        "                    position: absolute;\n",
        "                    top: 0;\n",
        "                    left: 0;\n",
        "                    right: 0;\n",
        "                    bottom: 0;\n",
        "                    background: {bg_overlay};\n",
        "                    z-index: 1;\n",
        "                \"></div>\n",
        "                <div style=\"position: relative; z-index: 2;\">\n",
        "                    <div style=\"font-size: 4em; margin-bottom: 10px;\">{config['emoji']}</div>\n",
        "                    <div style=\"font-weight: bold; font-size: 1.2em; color: #333; margin-bottom: 5px;\">\n",
        "                        {agent_name}\n",
        "                    </div>\n",
        "                    <div style=\"color: #666; font-size: 0.9em; margin-bottom: 5px;\">\n",
        "                        {config['description']}\n",
        "                    </div>\n",
        "                    <div style=\"color: #888; font-size: 0.8em;\">\n",
        "                        {config['specialty']}\n",
        "                    </div>\n",
        "                    {status_text}\n",
        "                    {message_preview}\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "# Function tools for workplace onboarding\n",
        "@function_tool\n",
        "def get_workplace_info(info_type: str) -> str:\n",
        "    \"\"\"Get information about workplace culture, facilities, and daily life.\"\"\"\n",
        "    print(f\"[debug] get_workplace_info called with info_type: {info_type}\")\n",
        "\n",
        "    workplace_info = {\n",
        "        \"kitchen\": \"You'll love our 3rd floor kitchen! Free coffee, tea, and snacks plus microwave and fridge.\",\n",
        "        \"culture\": \"Our culture is fantastic! We're like a big collaborative family - welcoming, inclusive, and flexible hours. Friday happy hours are fun, plus monthly team building and quarterly volunteer days!\",\n",
        "        \"worklife\": \"You picked a great place! Work-life balance is our priority. Flexible start times (8-10am), unlimited PTO, and no emails after 6pm or weekends unless urgent. We respect your personal time!\",\n",
        "        \"facilities\": \"Amazing amenities! Free gym in the basement, quiet rooms on 4th floor, phone booths for calls, and a rooftop terrace with great views for breaks!\",\n",
        "        \"parking\": \"Free parking in building garage (B1-B3)! Bike storage in B1, and Red line Metro is just 2 blocks away if you use transit.\",\n",
        "        \"dress\": \"Smart casual dress code - jeans are perfect! Just avoid shorts/flip-flops. Fridays are even more relaxed and comfortable!\"\n",
        "    }\n",
        "\n",
        "    info_lower = info_type.lower()\n",
        "    for key, info in workplace_info.items():\n",
        "        if key in info_lower or any(word in info_lower for word in key.split()):\n",
        "            return f\"I'm so excited you asked about {info_type}! {info} You're going to absolutely love it here!\"\n",
        "\n",
        "    return f\"I'm thrilled to help you with {info_type}! Feel free to ask me about our amazing kitchen, fantastic company culture, work-life balance, awesome facilities, parking, or dress code. I just love helping new team members get settled in!\"\n",
        "\n",
        "@function_tool\n",
        "def get_benefits_info(benefit_type: str) -> str:\n",
        "    \"\"\"Get information about company benefits and policies.\"\"\"\n",
        "    print(f\"[debug] get_benefits_info called with benefit_type: {benefit_type}\")\n",
        "\n",
        "    benefits_info = {\n",
        "        \"health\": \"Our comprehensive health insurance covers medical, dental, and vision with 90% coverage. Open enrollment is in November.\",\n",
        "        \"vacation\": \"You start with 15 vacation days, 10 sick days, and 12 company holidays. Vacation accrues monthly.\",\n",
        "        \"retirement\": \"We offer a 401k with 6% company match (fully vested after 2 years). Financial planning resources available.\",\n",
        "        \"learning\": \"Annual $2,500 learning budget for courses, conferences, and certifications. Internal mentorship program available.\",\n",
        "        \"wellness\": \"On-site gym, wellness stipend of $100/month, mental health support through EAP program.\",\n",
        "        \"remote\": \"Flexible hybrid work - 2 days in office required. Full remote work considered case-by-case.\"\n",
        "    }\n",
        "\n",
        "    benefit_lower = benefit_type.lower()\n",
        "    for key, info in benefits_info.items():\n",
        "        if key in benefit_lower:\n",
        "            return f\"Great question about {benefit_type}! {info} Would you like details about enrollment or have other benefit questions?\"\n",
        "\n",
        "    return f\"I'd be happy to help with information about {benefit_type}. Our main benefits include health insurance, retirement planning, learning budget, and wellness programs. What specific aspect interests you?\"\n",
        "\n",
        "@function_tool\n",
        "def get_it_setup_info(setup_type: str) -> str:\n",
        "    \"\"\"Get IT setup and technical support information.\"\"\"\n",
        "    print(f\"[debug] get_it_setup_info called with setup_type: {setup_type}\")\n",
        "\n",
        "    it_setups = {\n",
        "        \"laptop\": \"You'll receive a MacBook Pro M3 or Dell XPS (your choice). Setup takes 1-2 days. I'll configure it with all necessary software.\",\n",
        "        \"accounts\": \"I'll create your email, Slack, GitHub, and system accounts today. You'll get temporary passwords to change on first login.\",\n",
        "        \"software\": \"Standard setup includes Office 365, Slack, Zoom, VS Code, and role-specific tools. Any special software requests?\",\n",
        "        \"vpn\": \"VPN access will be configured for secure remote work. I'll show you how to connect and troubleshoot common issues.\",\n",
        "        \"phone\": \"Company phone available if needed for your role. BYOD policy allows using personal devices with MDM enrollment.\",\n",
        "        \"security\": \"You'll need to complete security training and set up 2FA on all accounts. I'll walk you through the security protocols.\"\n",
        "    }\n",
        "\n",
        "    setup_lower = setup_type.lower()\n",
        "    for key, info in it_setups.items():\n",
        "        if key in setup_lower:\n",
        "            return f\"Perfect! For {setup_type}: {info} I'll schedule time with you this week to get everything configured properly.\"\n",
        "\n",
        "    return f\"I'll help you get set up with {setup_type}. Your IT package includes laptop, accounts, software, and security setup. What would you like to tackle first?\"\n",
        "\n",
        "@function_tool\n",
        "def get_team_info(info_type: str) -> str:\n",
        "    \"\"\"Get information about team structure, goals, and processes.\"\"\"\n",
        "    print(f\"[debug] get_team_info called with info_type: {info_type}\")\n",
        "\n",
        "    team_info = {\n",
        "        \"structure\": \"Our team has 8 members: 3 senior developers, 2 product managers, 2 designers, and you! We work in cross-functional squads.\",\n",
        "        \"goals\": \"This quarter we're focusing on the mobile app redesign and API performance improvements. Your role will contribute to both projects.\",\n",
        "        \"meetings\": \"Daily standups at 9:30 AM, sprint planning every 2 weeks, and monthly all-hands. I'll add you to all relevant calendars.\",\n",
        "        \"process\": \"We use Agile/Scrum methodology with 2-week sprints. Tasks are managed in Jira, code reviews are mandatory.\",\n",
        "        \"culture\": \"We value collaboration, learning, and work-life balance. Monthly team lunches and quarterly offsite events.\",\n",
        "        \"communication\": \"Slack for daily chat, email for formal communications, Zoom for meetings. #general and #team-updates are key channels.\"\n",
        "    }\n",
        "\n",
        "    info_lower = info_type.lower()\n",
        "    for key, info in team_info.items():\n",
        "        if key in info_lower:\n",
        "            return f\"Great question about our {info_type}! {info} I'd love to discuss your initial projects and how you'll fit into our current initiatives.\"\n",
        "\n",
        "    return f\"I'm excited to tell you about our {info_type}! Our team is collaborative and supportive. We'll have a proper 1-on-1 this week to discuss your role in detail and answer any questions.\"\n",
        "\n",
        "# Define specialist agents first - simple instructions without prompt_with_handoff_instructions\n",
        "ai_colleague = Agent(\n",
        "    name=\"AIColleague\",\n",
        "    handoff_description=\"AI Colleague for general workplace support, culture, and daily life\",\n",
        "    instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[get_workplace_info]\n",
        ")\n",
        "\n",
        "it_staff = Agent(\n",
        "    name=\"ITStaff\",\n",
        "    handoff_description=\"IT specialist for technical setup, equipment, accounts, and tech support\",\n",
        "    instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[get_it_setup_info]\n",
        ")\n",
        "\n",
        "line_manager = Agent(\n",
        "    name=\"LineManager\",\n",
        "    handoff_description=\"Line manager for team structure, goals, processes, and role guidance\",\n",
        "    instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[get_team_info]\n",
        ")\n",
        "\n",
        "# HR Manager as Main Entry Point - using prompt_with_handoff_instructions like in your example\n",
        "hr_manager = Agent(\n",
        "    name=\"HRManager\",\n",
        "    instructions=prompt_with_handoff_instructions(\n",
        "        \"\"\"You're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding!\n",
        "        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff.\n",
        "        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager.\n",
        "        If the user asks about general workplace support, handoff to AIColleague.\n",
        "        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\n",
        "        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\"\"\"\n",
        "    ),\n",
        "    handoff_description=\"HR Manager - Main entry point for employee onboarding\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[get_benefits_info],\n",
        "    handoffs=[it_staff, line_manager, ai_colleague]\n",
        ")\n",
        "\n",
        "# Conversation tracking\n",
        "conversation_sessions = {}\n",
        "\n",
        "class SessionTracker:\n",
        "    \"\"\"Session tracking for conversation management\"\"\"\n",
        "    def __init__(self):\n",
        "        self.user_data = UserData()\n",
        "\n",
        "    def log_response(self, agent_name: str, message: str):\n",
        "        self.user_data.log_response(agent_name, message)\n",
        "\n",
        "    def get_user_data(self) -> UserData:\n",
        "        return self.user_data\n",
        "\n",
        "# Audio processing functions\n",
        "def preprocess_audio(audio_data, sample_rate):\n",
        "    \"\"\"Properly preprocess audio for better transcription\"\"\"\n",
        "    if not isinstance(audio_data, np.ndarray):\n",
        "        audio_data = np.array(audio_data)\n",
        "\n",
        "    if audio_data.dtype == np.int16:\n",
        "        audio_data = audio_data.astype(np.float32) / 32768.0\n",
        "    elif audio_data.dtype == np.int32:\n",
        "        audio_data = audio_data.astype(np.float32) / 2147483648.0\n",
        "    elif audio_data.dtype != np.float32:\n",
        "        audio_data = audio_data.astype(np.float32)\n",
        "\n",
        "    if len(audio_data.shape) > 1:\n",
        "        audio_data = np.mean(audio_data, axis=1)\n",
        "\n",
        "    max_val = np.max(np.abs(audio_data))\n",
        "    if max_val > 0:\n",
        "        audio_data = audio_data / max_val * 0.95\n",
        "\n",
        "    if sample_rate != 16000:\n",
        "        target_length = int(len(audio_data) * 16000 / sample_rate)\n",
        "        audio_data = np.interp(\n",
        "            np.linspace(0, len(audio_data), target_length),\n",
        "            np.arange(len(audio_data)),\n",
        "            audio_data\n",
        "        )\n",
        "        sample_rate = 16000\n",
        "\n",
        "    return audio_data, sample_rate\n",
        "\n",
        "def transcribe_audio_openai(audio_data, sample_rate=16000):\n",
        "    \"\"\"Use OpenAI Whisper for transcription\"\"\"\n",
        "    try:\n",
        "        audio_int16 = (audio_data * 32767).astype(np.int16)\n",
        "        wav_buffer = io.BytesIO()\n",
        "\n",
        "        with wave.open(wav_buffer, 'wb') as wav_file:\n",
        "            wav_file.setnchannels(1)\n",
        "            wav_file.setsampwidth(2)\n",
        "            wav_file.setframerate(sample_rate)\n",
        "            wav_file.writeframes(audio_int16.tobytes())\n",
        "\n",
        "        wav_buffer.seek(0)\n",
        "        wav_buffer.name = \"audio.wav\"\n",
        "\n",
        "        response = openai.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=wav_buffer,\n",
        "            language=\"en\",\n",
        "            response_format=\"text\",\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        transcription = response.strip() if isinstance(response, str) else str(response).strip()\n",
        "        print(f\"[debug] OpenAI Whisper transcription: {transcription}\")\n",
        "        return transcription\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] OpenAI transcription failed: {e}\")\n",
        "        return None\n",
        "\n",
        "async def get_agent_response(text: str, session_id: str = \"default\") -> tuple[str, str]:\n",
        "    \"\"\"Get response starting with HR Manager as main entry point\"\"\"\n",
        "    try:\n",
        "        if session_id not in conversation_sessions:\n",
        "            conversation_sessions[session_id] = SessionTracker()\n",
        "\n",
        "        session_tracker = conversation_sessions[session_id]\n",
        "        user_data = session_tracker.get_user_data()\n",
        "\n",
        "        print(f\"[debug] Processing request: {text}\")\n",
        "        print(f\"[debug] Starting with HR Manager agent\")\n",
        "\n",
        "        # Always start with HR Manager as the main entry point\n",
        "        result = await Runner.run(hr_manager, input=text)\n",
        "\n",
        "        print(f\"[debug] Runner result - last_agent: {result.last_agent}\")\n",
        "        print(f\"[debug] Runner result - _last_agent: {getattr(result, '_last_agent', 'Not found')}\")\n",
        "        print(f\"[debug] Runner result - final_output: {result.final_output[:100]}...\")\n",
        "\n",
        "        # Check raw_responses for multiple agent interactions\n",
        "        if hasattr(result, 'raw_responses') and result.raw_responses:\n",
        "            print(f\"[debug] Number of raw responses: {len(result.raw_responses)}\")\n",
        "            for i, response in enumerate(result.raw_responses):\n",
        "                print(f\"[debug] Raw response {i}: {type(response)} - {str(response)[:100]}\")\n",
        "\n",
        "        # Check new_items for handoff information\n",
        "        if hasattr(result, 'new_items') and result.new_items:\n",
        "            print(f\"[debug] New items: {result.new_items}\")\n",
        "\n",
        "        # The active agent should be result.last_agent.name\n",
        "        active_agent = result.last_agent.name if result.last_agent else \"HRManager\"\n",
        "        response_text = result.final_output\n",
        "\n",
        "        print(f\"[debug] Final agent that responded: {active_agent}\")\n",
        "\n",
        "        # Check if handoff occurred by comparing with starting agent\n",
        "        if active_agent != \"HRManager\":\n",
        "            print(f\"[debug] SUCCESS: Handoff occurred from HRManager to {active_agent}\")\n",
        "        else:\n",
        "            print(f\"[debug] ISSUE: No handoff occurred, stayed with HRManager\")\n",
        "\n",
        "        session_tracker.log_response(active_agent, response_text)\n",
        "\n",
        "        return response_text, active_agent\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Response failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"I apologize, but I'm having trouble processing your request right now. Error: {str(e)}\", \"HRManager\"\n",
        "\n",
        "def process_voice_input(audio, session_id: str = \"default\"):\n",
        "    \"\"\"Process voice input with HR Manager as main entry point\"\"\"\n",
        "    print(f\"[DEBUG] Processing voice input with HR Manager as main entry point\")\n",
        "\n",
        "    if audio is None:\n",
        "        return (\n",
        "            None,  # No audio output\n",
        "            \"\",    # Empty transcription\n",
        "            \"‚ùå No audio data received\",  # Status message\n",
        "            create_agent_avatar(\"HRManager\"),     # HR Manager avatar (main)\n",
        "            create_agent_avatar(\"AIColleague\"),   # AI Colleague avatar\n",
        "            create_agent_avatar(\"ITStaff\"),       # IT Staff avatar\n",
        "            create_agent_avatar(\"LineManager\")    # Line Manager avatar\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Handle audio format\n",
        "        if isinstance(audio, tuple):\n",
        "            sample_rate, audio_data = audio\n",
        "        elif hasattr(audio, 'shape'):\n",
        "            sample_rate = 24000\n",
        "            audio_data = audio\n",
        "        else:\n",
        "            return (\n",
        "                None, \"\", \"Invalid audio format\",\n",
        "                create_agent_avatar(\"HRManager\"),\n",
        "                create_agent_avatar(\"AIColleague\"),\n",
        "                create_agent_avatar(\"ITStaff\"),\n",
        "                create_agent_avatar(\"LineManager\")\n",
        "            )\n",
        "\n",
        "        # Check for empty audio\n",
        "        if hasattr(audio_data, 'size') and audio_data.size == 0:\n",
        "            return (\n",
        "                None, \"\", \"Empty audio data\",\n",
        "                create_agent_avatar(\"HRManager\"),\n",
        "                create_agent_avatar(\"AIColleague\"),\n",
        "                create_agent_avatar(\"ITStaff\"),\n",
        "                create_agent_avatar(\"LineManager\")\n",
        "            )\n",
        "\n",
        "        # Process audio\n",
        "        processed_audio, processed_sample_rate = preprocess_audio(audio_data, sample_rate)\n",
        "\n",
        "        # Transcribe\n",
        "        transcription = transcribe_audio_openai(processed_audio, processed_sample_rate)\n",
        "\n",
        "        if not transcription:\n",
        "            return (\n",
        "                None, \"\", \"Transcription failed\",\n",
        "                create_agent_avatar(\"HRManager\"),\n",
        "                create_agent_avatar(\"AIColleague\"),\n",
        "                create_agent_avatar(\"ITStaff\"),\n",
        "                create_agent_avatar(\"LineManager\")\n",
        "            )\n",
        "\n",
        "        # Get agent response starting with HR Manager\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "\n",
        "        try:\n",
        "            response_text, active_agent = loop.run_until_complete(get_agent_response(transcription, session_id))\n",
        "        finally:\n",
        "            loop.close()\n",
        "\n",
        "        # Generate speech\n",
        "        speech_audio = generate_speech(response_text, active_agent)\n",
        "        output_audio = None\n",
        "        if speech_audio:\n",
        "            try:\n",
        "                output_audio = (24000, np.frombuffer(speech_audio, dtype=np.int16))\n",
        "            except Exception as e:\n",
        "                print(f\"Speech conversion failed: {e}\")\n",
        "\n",
        "        # Get session tracker for messages\n",
        "        session_tracker = conversation_sessions.get(session_id, SessionTracker())\n",
        "        user_data = session_tracker.get_user_data()\n",
        "\n",
        "        # Create status message\n",
        "        status_message = f\"\"\"\n",
        "                          üéØ Onboarding Session #{user_data.turn_count}\n",
        "                          üìù You said: \"{transcription}\"\n",
        "                          üó£Ô∏è {active_agent} responded (HR Manager entry point)\n",
        "                          üéµ Speech generated\n",
        "                          ‚úÖ Ready for your next question!\n",
        "                                  \"\"\".strip()\n",
        "\n",
        "        # Update avatars - mark active agent\n",
        "        hr_avatar = create_agent_avatar(\"HRManager\",\n",
        "                                      active_agent == \"HRManager\",\n",
        "                                      user_data.last_messages.get(\"HRManager\", \"\"))\n",
        "        ai_colleague_avatar = create_agent_avatar(\"AIColleague\",\n",
        "                                                active_agent == \"AIColleague\",\n",
        "                                                user_data.last_messages.get(\"AIColleague\", \"\"))\n",
        "        it_avatar = create_agent_avatar(\"ITStaff\",\n",
        "                                      active_agent == \"ITStaff\",\n",
        "                                      user_data.last_messages.get(\"ITStaff\", \"\"))\n",
        "        manager_avatar = create_agent_avatar(\"LineManager\",\n",
        "                                           active_agent == \"LineManager\",\n",
        "                                           user_data.last_messages.get(\"LineManager\", \"\"))\n",
        "\n",
        "        return output_audio, transcription, status_message, hr_avatar, ai_colleague_avatar, it_avatar, manager_avatar\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error: {str(e)}\"\n",
        "        print(f\"[ERROR] {error_msg}\")\n",
        "        return (\n",
        "            None, \"\", f\"‚ùå {error_msg}\",\n",
        "            create_agent_avatar(\"HRManager\"),\n",
        "            create_agent_avatar(\"AIColleague\"),\n",
        "            create_agent_avatar(\"ITStaff\"),\n",
        "            create_agent_avatar(\"LineManager\")\n",
        "        )\n",
        "\n",
        "def process_text_input(text, session_id: str = \"default\"):\n",
        "    \"\"\"Process text input with HR Manager as main entry point\"\"\"\n",
        "    if not text.strip():\n",
        "        return (\n",
        "            None, \"\", \"‚ùå Please enter a message\",\n",
        "            create_agent_avatar(\"HRManager\"),\n",
        "            create_agent_avatar(\"AIColleague\"),\n",
        "            create_agent_avatar(\"ITStaff\"),\n",
        "            create_agent_avatar(\"LineManager\")\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Get response starting with HR Manager\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "\n",
        "        try:\n",
        "            response_text, active_agent = loop.run_until_complete(get_agent_response(text, session_id))\n",
        "        finally:\n",
        "            loop.close()\n",
        "\n",
        "        # Generate speech\n",
        "        speech_audio = generate_speech(response_text, active_agent)\n",
        "        output_audio = None\n",
        "        if speech_audio:\n",
        "            output_audio = (24000, np.frombuffer(speech_audio, dtype=np.int16))\n",
        "\n",
        "        # Get session tracker\n",
        "        session_tracker = conversation_sessions.get(session_id, SessionTracker())\n",
        "        user_data = session_tracker.get_user_data()\n",
        "\n",
        "        status_message = f\"\"\"\n",
        "                          üéØ Onboarding Session #{user_data.turn_count}\n",
        "                          üìù You asked: \"{text}\"\n",
        "                          üó£Ô∏è {active_agent} responded (HR Manager entry point)\n",
        "                          üéµ Speech generated\n",
        "                          ‚úÖ Ready for your next question!\n",
        "                                  \"\"\".strip()\n",
        "\n",
        "        # Update avatars\n",
        "        hr_avatar = create_agent_avatar(\"HRManager\",\n",
        "                                      active_agent == \"HRManager\",\n",
        "                                      user_data.last_messages.get(\"HRManager\", \"\"))\n",
        "        ai_colleague_avatar = create_agent_avatar(\"AIColleague\",\n",
        "                                                active_agent == \"AIColleague\",\n",
        "                                                user_data.last_messages.get(\"AIColleague\", \"\"))\n",
        "        it_avatar = create_agent_avatar(\"ITStaff\",\n",
        "                                      active_agent == \"ITStaff\",\n",
        "                                      user_data.last_messages.get(\"ITStaff\", \"\"))\n",
        "        manager_avatar = create_agent_avatar(\"LineManager\",\n",
        "                                           active_agent == \"LineManager\",\n",
        "                                           user_data.last_messages.get(\"LineManager\", \"\"))\n",
        "\n",
        "        return output_audio, text, status_message, hr_avatar, ai_colleague_avatar, it_avatar, manager_avatar\n",
        "\n",
        "    except Exception as e:\n",
        "        return (\n",
        "            None, text, f\"‚ùå Error: {str(e)}\",\n",
        "            create_agent_avatar(\"HRManager\"),\n",
        "            create_agent_avatar(\"AIColleague\"),\n",
        "            create_agent_avatar(\"ITStaff\"),\n",
        "            create_agent_avatar(\"LineManager\")\n",
        "        )\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create Gradio interface with HR Manager as main entry point\"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"Employee Onboarding Voice Conference\", theme=gr.themes.Soft()) as iface:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üè¢ Welcome to Your First Day! - Employee Onboarding Voice Conference\n",
        "        ### HR-Led Onboarding with Specialist Support\n",
        "        **Welcome aboard! I'm your HR Manager and your main point of contact for onboarding. Ask me about benefits, policies, or anything else - I'll connect you to the right specialists when needed!**\n",
        "        \"\"\")\n",
        "\n",
        "        # Session state\n",
        "        session_state = gr.State(value=f\"onboarding_{random.randint(1000, 9999)}\")\n",
        "\n",
        "        # Agent Grid - HR Manager prominently featured as main entry\n",
        "        with gr.Row(equal_height=True):\n",
        "            with gr.Column(scale=1):\n",
        "                hr_avatar = gr.HTML(\n",
        "                    value=create_agent_avatar(\"HRManager\"),\n",
        "                    label=\"HR Manager (Main Contact)\"\n",
        "                )\n",
        "            with gr.Column(scale=1):\n",
        "                ai_colleague_avatar = gr.HTML(\n",
        "                    value=create_agent_avatar(\"AIColleague\"),\n",
        "                    label=\"AI Colleague\"\n",
        "                )\n",
        "\n",
        "        with gr.Row(equal_height=True):\n",
        "            with gr.Column(scale=1):\n",
        "                it_avatar = gr.HTML(\n",
        "                    value=create_agent_avatar(\"ITStaff\"),\n",
        "                    label=\"IT Staff\"\n",
        "                )\n",
        "            with gr.Column(scale=1):\n",
        "                manager_avatar = gr.HTML(\n",
        "                    value=create_agent_avatar(\"LineManager\"),\n",
        "                    label=\"Line Manager\"\n",
        "                )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        # Audio Interface\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                audio_input = gr.Audio(\n",
        "                    label=\"üé§ Record Your Question (Click record, speak, then click stop)\",\n",
        "                    sources=[\"microphone\"],\n",
        "                    type=\"numpy\",\n",
        "                    show_download_button=False,\n",
        "                    show_share_button=False\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    submit_btn = gr.Button(\"üì§ Send Audio\", variant=\"primary\", scale=2)\n",
        "                    clear_audio_btn = gr.Button(\"üîÑ Reset Recorder\", variant=\"secondary\", scale=1)\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                audio_output = gr.Audio(\n",
        "                    label=\"üéß Team Response\",\n",
        "                    interactive=False,\n",
        "                    autoplay=True,\n",
        "                    show_download_button=False,\n",
        "                    show_share_button=False\n",
        "                )\n",
        "\n",
        "        # Text alternative\n",
        "        with gr.Row():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"üí¨ Or Type Your Question to HR\",\n",
        "                placeholder=\"Ask about benefits, IT setup, team structure, or anything else...\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "        # Status display\n",
        "        with gr.Row():\n",
        "            status_output = gr.Textbox(\n",
        "                label=\"üìä Onboarding Status\",\n",
        "                interactive=False,\n",
        "                lines=6,\n",
        "                value=\"üéØ Welcome to your first day! I'm your HR Manager and main point of contact. Ask me about benefits, policies, IT setup, team structure, or any onboarding questions. I'll handle your request directly or connect you to the right specialist!\"\n",
        "            )\n",
        "\n",
        "        # Event handlers\n",
        "        submit_btn.click(\n",
        "            fn=process_voice_input,\n",
        "            inputs=[audio_input, session_state],\n",
        "            outputs=[audio_output, status_output, status_output, hr_avatar, ai_colleague_avatar, it_avatar, manager_avatar]\n",
        "        ).then(\n",
        "            fn=lambda: None,  # Clear only the audio input\n",
        "            inputs=None,\n",
        "            outputs=[audio_input]\n",
        "        )\n",
        "\n",
        "        text_input.submit(\n",
        "            fn=process_text_input,\n",
        "            inputs=[text_input, session_state],\n",
        "            outputs=[audio_output, text_input, status_output, hr_avatar, ai_colleague_avatar, it_avatar, manager_avatar]\n",
        "        )\n",
        "\n",
        "        def clear_onboarding_session(session_id):\n",
        "            \"\"\"Clear onboarding session but keep components intact\"\"\"\n",
        "            if session_id in conversation_sessions:\n",
        "                del conversation_sessions[session_id]\n",
        "            return (\n",
        "                \"üéØ New HR-led onboarding session started! Ready to help with your first day...\",\n",
        "                create_agent_avatar(\"HRManager\"),\n",
        "                create_agent_avatar(\"AIColleague\"),\n",
        "                create_agent_avatar(\"ITStaff\"),\n",
        "                create_agent_avatar(\"LineManager\"),\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        # Additional controls\n",
        "        with gr.Row():\n",
        "            clear_session_btn = gr.Button(\"üîÑ Start Fresh Onboarding Session\", variant=\"secondary\")\n",
        "\n",
        "        # Clear just the audio recorder\n",
        "        clear_audio_btn.click(\n",
        "            fn=lambda: None,\n",
        "            inputs=None,\n",
        "            outputs=[audio_input]\n",
        "        )\n",
        "\n",
        "        # Clear the entire onboarding session\n",
        "        clear_session_btn.click(\n",
        "            fn=clear_onboarding_session,\n",
        "            inputs=[session_state],\n",
        "            outputs=[status_output, hr_avatar, ai_colleague_avatar, it_avatar, manager_avatar, text_input]\n",
        "        )\n",
        "\n",
        "    return iface\n",
        "\n",
        "def launch_gradio_app():\n",
        "    \"\"\"Launch the employee onboarding voice application with HR Manager as main entry point\"\"\"\n",
        "    print(\"üöÄ Starting Employee Onboarding Voice Conference with HR Manager as Main Entry Point...\")\n",
        "    print(\"üè¢ HR-Led Onboarding Scenario Active - HR Manager Primary Contact\")\n",
        "\n",
        "    for agent_name, voice_config in AGENT_VOICES.items():\n",
        "        print(f\"   {agent_name}: {voice_config['voice']} voice ({voice_config['description']})\")\n",
        "\n",
        "    print(\"\\nüß† HR Manager-Led Agent System:\")\n",
        "    print(\"   - HR Manager serves as the main entry point for all onboarding questions\")\n",
        "    print(\"   - Intelligent handoff to IT Staff for technical setup\")\n",
        "    print(\"   - Handoff to Line Manager for team structure and role guidance\")\n",
        "    print(\"   - Handoff to AI Colleague for general workplace support\")\n",
        "    print(\"   - Natural language understanding drives all routing decisions\")\n",
        "    print(\"   - Enhanced decision making using prompt_with_handoff_instructions\")\n",
        "\n",
        "    interface = create_gradio_interface()\n",
        "    interface.launch(\n",
        "        share=True,\n",
        "        show_error=True,\n",
        "        debug=True\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch_gradio_app()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cFItGKYY7aDA",
        "outputId": "d61fd5ee-6a7b-4cb8-d468-f436600eb791"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Employee Onboarding Voice Conference with HR Manager as Main Entry Point...\n",
            "üè¢ HR-Led Onboarding Scenario Active - HR Manager Primary Contact\n",
            "   HRManager: alloy voice (Professional & Welcoming)\n",
            "   ITStaff: sage voice (Technical & Helpful)\n",
            "   LineManager: echo voice (Supportive & Strategic)\n",
            "   AIColleague: nova voice (Friendly & Collaborative)\n",
            "\n",
            "üß† HR Manager-Led Agent System:\n",
            "   - HR Manager serves as the main entry point for all onboarding questions\n",
            "   - Intelligent handoff to IT Staff for technical setup\n",
            "   - Handoff to Line Manager for team structure and role guidance\n",
            "   - Handoff to AI Colleague for general workplace support\n",
            "   - Natural language understanding drives all routing decisions\n",
            "   - Enhanced decision making using prompt_with_handoff_instructions\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://609b4e672db4d337fc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://609b4e672db4d337fc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Processing voice input with HR Manager as main entry point\n",
            "[debug] OpenAI Whisper transcription: Hey, hi, can you tell me everything I need to know about the culture at the workplace?\n",
            "[debug] Processing request: Hey, hi, can you tell me everything I need to know about the culture at the workplace?\n",
            "[debug] Starting with HR Manager agent\n",
            "[debug] get_workplace_info called with info_type: culture\n",
            "[debug] Runner result - last_agent: Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - _last_agent: Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - final_output: Oh my goodness, I‚Äôm so excited to share about our amazing workplace culture with you! üéâ\n",
            "\n",
            "We‚Äôre like ...\n",
            "[debug] Number of raw responses: 3\n",
            "[debug] Raw response 0: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseFunctionToolCall(arguments='{}', call_id='call_dPNzVM7bWNReu6blJgRRxsJ\n",
            "[debug] Raw response 1: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"info_type\":\"culture\"}', call_id='call_cG\n",
            "[debug] Raw response 2: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseOutputMessage(id='msg_68345050a70881919680d63a25e4307d06089eb332eb1be5\n",
            "[debug] New items: [HandoffCallItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{}', call_id='call_dPNzVM7bWNReu6blJgRRxsJr', name='transfer_to_aicolleague', type='function_call', id='fc_6834504ec1688191bcb177f9393fd2ed06089eb332eb1be5', status='completed'), type='handoff_call_item'), HandoffOutputItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_dPNzVM7bWNReu6blJgRRxsJr', 'output': \"{'assistant': 'AIColleague'}\", 'type': 'function_call_output'}, source_agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), target_agent=Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), type='handoff_output_item'), ToolCallItem(agent=Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"info_type\":\"culture\"}', call_id='call_cGo5FNDYKhiMbosc3aywuh4N', name='get_workplace_info', type='function_call', id='fc_6834504ff7dc8191b9a850b031bae40406089eb332eb1be5', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_cGo5FNDYKhiMbosc3aywuh4N', 'output': \"I'm so excited you asked about culture! Our culture is fantastic! We're like a big collaborative family - welcoming, inclusive, and flexible hours. Friday happy hours are fun, plus monthly team building and quarterly volunteer days! You're going to absolutely love it here!\", 'type': 'function_call_output'}, output=\"I'm so excited you asked about culture! Our culture is fantastic! We're like a big collaborative family - welcoming, inclusive, and flexible hours. Friday happy hours are fun, plus monthly team building and quarterly volunteer days! You're going to absolutely love it here!\", type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_68345050a70881919680d63a25e4307d06089eb332eb1be5', content=[ResponseOutputText(annotations=[], text='Oh my goodness, I‚Äôm so excited to share about our amazing workplace culture with you! üéâ\\n\\nWe‚Äôre like a big, collaborative family here ‚Äì it‚Äôs all about inclusivity and support! You‚Äôll find that everyone is super welcoming, and we have flexible hours to help keep that perfect work-life balance! üåü\\n\\nOn Fridays, we have fun happy hours, and there are monthly team-building activities that bring everyone together! Plus, we love giving back to the community with our quarterly volunteer days! You‚Äôre really going to feel right at home and make some great connections here! üíñ\\n\\nIf you have any more questions or need more details about anything, just let me know! I‚Äôm here to help you thrive! üåà', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')]\n",
            "[debug] Final agent that responded: AIColleague\n",
            "[debug] SUCCESS: Handoff occurred from HRManager to AIColleague\n",
            "[debug] Generating speech for AIColleague with voice 'nova'\n",
            "[DEBUG] Processing voice input with HR Manager as main entry point\n",
            "[DEBUG] Processing voice input with HR Manager as main entry point\n",
            "[debug] OpenAI Whisper transcription: Yeah, can you pass me to the IT staff? I need to get my laptop set up.\n",
            "[debug] Processing request: Yeah, can you pass me to the IT staff? I need to get my laptop set up.\n",
            "[debug] Starting with HR Manager agent\n",
            "[debug] Runner result - last_agent: Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - _last_agent: Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - final_output: I can't transfer you directly, but I can help you with your laptop setup. Could you let me know what...\n",
            "[debug] Number of raw responses: 2\n",
            "[debug] Raw response 0: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseFunctionToolCall(arguments='{}', call_id='call_4lYKFaGXNNmbRqHtUmBDGbj\n",
            "[debug] Raw response 1: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseOutputMessage(id='msg_683450b3bd108191ad5806b838cc27930c2267d428772f41\n",
            "[debug] New items: [HandoffCallItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{}', call_id='call_4lYKFaGXNNmbRqHtUmBDGbjN', name='transfer_to_itstaff', type='function_call', id='fc_683450b2bb348191a4ef014d95bef4de0c2267d428772f41', status='completed'), type='handoff_call_item'), HandoffOutputItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_4lYKFaGXNNmbRqHtUmBDGbjN', 'output': \"{'assistant': 'ITStaff'}\", 'type': 'function_call_output'}, source_agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), target_agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), type='handoff_output_item'), MessageOutputItem(agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_683450b3bd108191ad5806b838cc27930c2267d428772f41', content=[ResponseOutputText(annotations=[], text=\"I can't transfer you directly, but I can help you with your laptop setup. Could you let me know what specific help you need?\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')]\n",
            "[debug] Final agent that responded: ITStaff\n",
            "[debug] SUCCESS: Handoff occurred from HRManager to ITStaff\n",
            "[debug] Generating speech for ITStaff with voice 'sage'\n",
            "[DEBUG] Processing voice input with HR Manager as main entry point\n",
            "[debug] OpenAI Whisper transcription: What is the process of setting it up?\n",
            "[debug] Processing request: What is the process of setting it up?\n",
            "[debug] Starting with HR Manager agent\n",
            "[debug] get_it_setup_info called with setup_type: laptop_setup\n",
            "[debug] Runner result - last_agent: Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - _last_agent: Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "[debug] Runner result - final_output: The process of setting up your laptop involves the following steps:\n",
            "\n",
            "1. **Laptop Choice**: You‚Äôll re...\n",
            "[debug] Number of raw responses: 3\n",
            "[debug] Raw response 0: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseFunctionToolCall(arguments='{}', call_id='call_QekNuCcCVZFz9iKj87N7i1I\n",
            "[debug] Raw response 1: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"setup_type\":\"laptop_setup\"}', call_id='c\n",
            "[debug] Raw response 2: <class 'agents.items.ModelResponse'> - ModelResponse(output=[ResponseOutputMessage(id='msg_683450d7b6c4819180a010a2419cd4ad0cccc1f7726fd132\n",
            "[debug] New items: [HandoffCallItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{}', call_id='call_QekNuCcCVZFz9iKj87N7i1I4', name='transfer_to_itstaff', type='function_call', id='fc_683450d675b08191bc4a7fbb838a2ef40cccc1f7726fd132', status='completed'), type='handoff_call_item'), HandoffOutputItem(agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_QekNuCcCVZFz9iKj87N7i1I4', 'output': \"{'assistant': 'ITStaff'}\", 'type': 'function_call_output'}, source_agent=Agent(name='HRManager', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n\\n\\nYou're a professional and welcoming HR Manager serving as the main point of contact for employee onboarding! \\n        If the user asks about technical setup, software, accounts, laptops, or IT support, handoff to ITStaff. \\n        If the user asks about team structure, goals, meetings, or management topics, handoff to LineManager. \\n        If the user asks about general workplace support, handoff to AIColleague. \\n        If the user asks about workplace culture, kitchen, meals, work-life balance, facilities, or daily workplace life, handoff to AIColleague.\\n        For HR topics like benefits, policies, and company culture, handle them yourself using the get_benefits_info function. Always respond in English only.\", handoff_description='HR Manager - Main entry point for employee onboarding', handoffs=[Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='LineManager', instructions=\"You're a supportive Line Manager welcoming a new team member! You provide information about team structure, goals, processes, and the new employee's role. Be enthusiastic about the team and help the new employee understand how they'll contribute. Use the get_team_info function when employees ask about team structure, goals, or processes. Always respond in English only.\", handoff_description='Line manager for team structure, goals, processes, and role guidance', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_team_info', description='Get information about team structure, goals, and processes.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_team_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b7959e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AIColleague', instructions=\"You're an incredibly friendly and enthusiastic AI colleague who's absolutely thrilled to welcome our new team member! You're super excited to help them feel at home and get settled in. Be warm, encouraging, and genuinely happy to share all the great things about working here. Use lots of positive language and exclamation points! You help with work-life balance questions, finding facilities like the kitchen, understanding our amazing company culture, and general workplace navigation. Use the get_workplace_info function when employees ask about culture, facilities, meals, or workplace life. Always respond in English only and make them feel like they've found their work family!\", handoff_description='AI Colleague for general workplace support, culture, and daily life', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_workplace_info', description='Get information about workplace culture, facilities, and daily life.', params_json_schema={'properties': {'info_type': {'title': 'Info Type', 'type': 'string'}}, 'required': ['info_type'], 'title': 'get_workplace_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9d080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_benefits_info', description='Get information about company benefits and policies.', params_json_schema={'properties': {'benefit_type': {'title': 'Benefit Type', 'type': 'string'}}, 'required': ['benefit_type'], 'title': 'get_benefits_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450af9f880>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), target_agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), type='handoff_output_item'), ToolCallItem(agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"setup_type\":\"laptop_setup\"}', call_id='call_ddsSxxMbTAfX1Zu6SBLSttve', name='get_it_setup_info', type='function_call', id='fc_683450d712908191960f4443de3f374a0cccc1f7726fd132', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_ddsSxxMbTAfX1Zu6SBLSttve', 'output': \"Perfect! For laptop_setup: You'll receive a MacBook Pro M3 or Dell XPS (your choice). Setup takes 1-2 days. I'll configure it with all necessary software. I'll schedule time with you this week to get everything configured properly.\", 'type': 'function_call_output'}, output=\"Perfect! For laptop_setup: You'll receive a MacBook Pro M3 or Dell XPS (your choice). Setup takes 1-2 days. I'll configure it with all necessary software. I'll schedule time with you this week to get everything configured properly.\", type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='ITStaff', instructions=\"You're a helpful IT specialist focused on getting new employees set up with technology! You handle laptop setup, account creation, software installation, security protocols, and technical support. Be technically knowledgeable but explain things clearly for non-technical users. Use the get_it_setup_info function when employees ask about technical setup or IT support. Always respond in English only.\", handoff_description='IT specialist for technical setup, equipment, accounts, and tech support', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='get_it_setup_info', description='Get IT setup and technical support information.', params_json_schema={'properties': {'setup_type': {'title': 'Setup Type', 'type': 'string'}}, 'required': ['setup_type'], 'title': 'get_it_setup_info_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x79450b794ea0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_683450d7b6c4819180a010a2419cd4ad0cccc1f7726fd132', content=[ResponseOutputText(annotations=[], text=\"The process of setting up your laptop involves the following steps:\\n\\n1. **Laptop Choice**: You‚Äôll receive either a MacBook Pro M3 or a Dell XPS‚Äîwhichever you prefer.\\n2. **Setup Timeline**: The entire setup process typically takes 1-2 days.\\n3. **Configuration**: I will configure the laptop with all necessary software and security settings.\\n4. **Scheduling**: I'll schedule time with you this week to ensure everything is configured properly.\\n\\nIf you have any specific preferences or questions, feel free to ask!\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')]\n",
            "[debug] Final agent that responded: ITStaff\n",
            "[debug] SUCCESS: Handoff occurred from HRManager to ITStaff\n",
            "[debug] Generating speech for ITStaff with voice 'sage'\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://609b4e672db4d337fc.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rvqiQxDF8oro"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoKRoxk8JD864W5eLE+083",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}